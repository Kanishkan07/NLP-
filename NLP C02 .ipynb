{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e39c5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48b5603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.cli.info.info(model: Optional[str] = None, *, markdown: bool = False, silent: bool = True, exclude: Optional[List[str]] = None, url: bool = False) -> Union[str, dict]>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0df37ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "221d3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tesla is looking to buy an EV and hybrid cars for $5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "570a639e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "to PART aux\n",
      "buy VERB xcomp\n",
      "an DET det\n",
      "EV PROPN nmod\n",
      "and CCONJ cc\n",
      "hybrid ADJ conj\n",
      "cars NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM nmod\n",
      "5000 NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d279a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxiliary'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('aux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b2ee8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x208052dd640>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x20802652d00>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x208173ad580>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x20820d4dc00>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2080264aa40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x20816faaeb0>)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6dd31880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8c0d6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3fd99f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PART'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de2f07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aux'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0af4f1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].lemma_   #rootword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2add07b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[4].lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe691ea6",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad4dd8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On My Way is an album By Allen Walker which pubg used in game in 2018 at 12.00 IST'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = \"On My Way is an album By Allen Walker which pubg used in game in 2018 at 12.00 IST\"\n",
    "my_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97626ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "201f66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "On My Way is an album By Allen Walker which pubg used in game in 2018 at 12.00 IST"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57eec76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On | My | Way | is | an | album | By | Allen | Walker | which | pubg | used | in | game | in | 2018 | at | 12.00 | IST | "
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "  print(token.text, end = ' | ') #end is for splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56bd90f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20580\\211150030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"yes\"\u001b[0m \u001b[1;31m# We cant reassign tokens (interchange)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "doc2[3] = \"yes\" # We cant reassign tokens (interchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec376054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IST - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in doc2.ents:\n",
    "  print(ent.text+ ' - ' + ent.label_+' - '+str(spacy.explain(ent.label_)) )  # only a particular named entities eg. like name, place, organizations etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a93ebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0cbce5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2.ents)  #4 Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe55bc",
   "metadata": {},
   "source": [
    "Both stemming and lemmatization will try to reduce the given word to a root node.\n",
    "STEMMING\n",
    "Stemming is a word reduction focuses on removing word endings (suffixes) to obtain a base form, often resulting in non-dictionary words.\n",
    "Lemmatization\n",
    "we can reach out to the base form of any word which will be meaningful in nature.\n",
    "The base from here is called the Lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21e5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73ee394",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b80acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"happily\", \"likely\", \"constructive\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11ac74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happili', 'like', 'construct']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words = [porter_stemmer.stem(word) for word in words]   #for stemming each word\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04006db",
   "metadata": {},
   "source": [
    "# NLP for GREEK language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3bc7b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "405549ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('el_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "308318db",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(\"Εγώ έχω έναν σκύλο και μία γάτα. Egó ého énan skílo ke mía gáta.\") #I have a dog and a cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5ecab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Εγώ VERB ROOT\n",
      "έχω ADV advmod\n",
      "έναν NOUN compound\n",
      "σκύλο ADV advmod\n",
      "και PROPN compound\n",
      "μία PROPN compound\n",
      "γάτα NOUN oprd\n",
      ". PUNCT punct\n",
      "Egó NOUN compound\n",
      "ého PROPN compound\n",
      "énan PROPN nsubj\n",
      "skílo PROPN ROOT\n",
      "ke PROPN compound\n",
      "mía PROPN compound\n",
      "gáta PROPN dobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "    print(token.text, token.pos_ ,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3b26a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "και"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "03a3cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Εγώ | έχω | έναν | σκύλο | και | μία | γάτα | . | Egó | ého | énan | skílo | ke | mía | gáta | . | "
     ]
    }
   ],
   "source": [
    "for token in doc3:\n",
    "  print(token.text, end = ' | ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1593ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
